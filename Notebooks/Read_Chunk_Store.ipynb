{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d36aaf56-14e8-43bd-84f1-736df0986696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_docling import DoclingLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcb9fe72-785f-4e2e-8a93-25bf0e35cea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (794 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (750 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3198 > 512). Running this sequence through the model will result in indexing errors\n",
      "C:\\Users\\ngtia\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ngtia\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2522 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "loaders = []\n",
    "docs = []\n",
    "#define the path for different types of documents. Create the functions to read from different file types if needed\n",
    "pdf_file_path = \"../Data/Budget2024_Documents/\"\n",
    "\n",
    "def read_PDF_files_in_folder(folder_path):\n",
    "    try:\n",
    "        for filename in os.listdir(folder_path):\n",
    "            filepath = os.path.join(folder_path, filename)\n",
    "            loaders.append(DoclingLoader(file_path = filepath))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error has occured: {e}\")\n",
    "\n",
    "\n",
    "read_PDF_files_in_folder(pdf_file_path)\n",
    "\n",
    "\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e3256a-848b-4adc-acc0-6816b910706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3021d510-90b6-42be-88b7-21a02041baca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "69428c05-a462-40c4-ac22-2faf7d10c147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store split chunks into vector db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "938ef05a-c8d4-4347-b437-687c3882bd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngtia\\AppData\\Local\\Temp\\ipykernel_6188\\2803807967.py:7: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding = OpenAIEmbeddings(model = \"text-embedding-3-small\")\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']\n",
    "embedding = OpenAIEmbeddings(model = \"text-embedding-3-small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8f57e0d-6930-49fd-9d1e-c1664bb9e8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "persist_directory = '../Data/Chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee79c06e-1720-4cf1-bd6f-530717c194c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.utils import filter_complex_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f89df76-9459-41b9-b3f7-47b56768aff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=filter_complex_metadata(splits),\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa378ff6-ecea-4d04-953e-d646e4dd41eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
